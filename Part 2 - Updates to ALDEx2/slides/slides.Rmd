---
title: "Beyond Normalization: Incorporating Scale Uncertainty in ALDEx2"
author: "Michelle Nixon"
date: "May 13, 2024"
always_allow_html: true
output:
  beamer_presentation:
    theme: "Frankfurt"
    keep_tex: true
header-includes:
  - \usepackage{dcolumn}
  - \usepackage{longtable,booktabs}
  - \makeatletter\def\fnum@table{\usebeamercolor{caption name}\usebeamerfont*{caption name}\tablename~\thetable}\makeatother
  - \usepackage{fvextra}
  - \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  fig.align = 'center')
library(formatR)
```

```{r, include=FALSE}
knitr::opts_knit$set(root.dir = "C:\\Users\\map5672\\OneDrive - The Pennsylvania State University\\Documents 1\\GitHub\\michellepistner\\glbio-2024-scale-workshop")
knitr::opts_chunk$set(tidy.opts = list(width.cutoff = 60), tidy = TRUE)
```


## Recap: Sequencing depth can confound conclusions.

\begin{table}[h!]
\centering
\begin{tabular}{|r|c c c| c|}
\hline
\textcolor{gray}{Observed data (Y)} & Sample 1 & Sample 2 & Sample 3  &\\
\hline
Condition & Health & Health & Disease & \textcolor{gray}{Conclusion}\\
\hline
Entity 1 & 5 & 10 & 100 & \textcolor{gray}{Increase}\\
Entity 2 & 10 & 25 & 3 & \textcolor{gray}{Decrease}\\
Entity 3 & 0 & 1 & 8 & \textcolor{gray}{Increase}\\
Entity 4 & 0 & 0 & 19 &\textcolor{gray}{Increase}\\
\hline
\textcolor{gray}{Sequencing Depth} & \textcolor{gray}{15} & \textcolor{gray}{36} & \textcolor{gray}{130} &\\
\hline
\end{tabular}
\end{table}


## This can mislead analyses.

\begin{table}[h!]
\centering
\begin{tabular}{|r|c c c| c|}
\hline
\textcolor{gray}{System data (W)} & Sample 1 & Sample 2 & Sample 3  & \\
\hline
Condition & Health & Health & Disease & \textcolor{gray}{Conclusion}\\
\hline
Entity 1 & 227 & 351 & 154 & \textcolor{gray}{Decrease}\\
Entity 2 & 684 & 891 & 3 & \textcolor{gray}{Decrease}\\
Entity 3 & 48 & 32 & 15 & \textcolor{gray}{Decrease}\\
Entity 4 & 43 & 39  & 27 &\textcolor{gray}{Decrease}\\
\hline
\textcolor{gray}{Scale ($W^\perp$)} & \textcolor{gray}{1,002} & \textcolor{gray}{1,313} & \textcolor{gray}{200} &\\
\hline
\end{tabular}
\end{table}

## ... and lead to unacknowledged bias.

\begin{figure}
  \centering
  \includegraphics[width=4.5in]{figures/unacknowledged_bias.pdf}
\end{figure}

# Problem Set-Up

## Observed Data as a Sample from the System

\begin{figure}
  \centering
  \includegraphics[width=4.5in]{figures/intro-fig-first.png}
\end{figure}

## Observed Data as a Sample from the System

\begin{figure}
  \centering
  \includegraphics[width=4.5in]{figures/intro-fig-full.png}
\end{figure}

## Notation

- $\mathbf{Y}$: a measurement of the underlying system $\mathbf{W}$.


$$\mathbf{W}_{dn} = \underbrace{\mathbf{W}_{dn}^\parallel}_{\text{composition}} \times  \underbrace{W_n^\perp}_{\text{scale}}$$

\textcolor{white}{- **Compostion:** $\mathbf{W}_{dn}^\parallel = \frac{\mathbf{W}_{dn}}{\sum_{d=1}^D \mathbf{W}_{dn}}$}

\textcolor{white}{- **Scale:** $W_n^\perp = \sum_{d=1}^D \mathbf{W}_{dn}$}


## Notation

- $\mathbf{Y}$: a measurement of the underlying system $\mathbf{W}$.


$$\mathbf{W}_{dn} = \underbrace{\mathbf{W}_{dn}^\parallel}_{\text{composition}} \times  \underbrace{W_n^\perp}_{\text{scale}}$$

- **Compostion:** $\mathbf{W}_{dn}^\parallel = \frac{\mathbf{W}_{dn}}{\sum_{d=1}^D \mathbf{W}_{dn}}$

- **Scale:** $W_n^\perp = \sum_{d=1}^D \mathbf{W}_{dn}$


## Example: Notation

- Consider a simple study of the microbiome pre/post antibiotic administration.

\vspace{0.05in}

\begin{table}[h!]
\centering
\begin{tabular}{|r|c c c| }
\hline
\textcolor{gray}{System data ($W^\parallel$)} & Sample 1 & Sample 2 & Sample 3\\
\hline
Condition & Pre & Pre & Post\\
\hline
Entity 1 & 0.27 & 0.27 & 0.77 \\
Entity 2 & 0.68 & 0.68 & 0.02 \\
Entity 3 & 0.05 & 0.02 & 0.08 \\
Entity 4 & 0.04 & 0.03  & 0.13 \\
\hline
\textcolor{gray}{Scale ($W^\perp$)} & \textcolor{gray}{1,002} & \textcolor{gray}{1,313} & \textcolor{gray}{200}\\
\hline
\end{tabular}
\end{table}

## Differential Abundance/Expression Analysis

- **Question:** How do entities (e.g., taxa or genes) change between conditions?

- $\boldsymbol{\theta}$: what we want to estimate. \textcolor{white}{(Log Fold Change)}

\vspace{.125in}


\begin{equation*}
\textcolor{white}{\theta_d = \text{mean}_{\text{case}}(\log \mathbf{W}_{dn}) - \text{mean}_{\text{control}}(\log \mathbf{W}_{dn})}
\end{equation*}

## Differential Abundance/Expression Analysis

- **Question:** How do entities (e.g., taxa or genes) change between conditions?

- $\boldsymbol{\theta}$: what we want to estimate. \textcolor{gray}{(Log Fold Change)}

\vspace{.25in}


\begin{equation*}
\theta_d = \text{mean}_{\text{case}}(\log \mathbf{W}_{dn}) - \text{mean}_{\text{control}}(\log \mathbf{W}_{dn})
\end{equation*}


## The Original ALDEx2 Model

\textbf{Step 1: Model Sampling Uncertainty}
\begin{align*}
\mathbf{Y}_{\cdot n} &\sim \text{Multinomial}(\mathbf{W}_{\cdot n}^\parallel)\\
\mathbf{W}_{\cdot n}^\parallel &\sim \text{Dirichlet}(\alpha)
\end{align*}

\textbf{Step 2: Centered Log-Ratio Transformation}
\begin{equation*}
\log \mathbf{W}_{\cdot n} = \left[\log \mathbf{W}_{1n}^\parallel - \text{mean}(\log \mathbf{W}_{\cdot n}^\parallel), ..., \log \mathbf{W}_{Dn}^\parallel - \text{mean}(\log \mathbf{W}_{\cdot n}^\parallel) \right]
\end{equation*}

\textbf{Step 3: Calculate LFCs and Test if Different from Zero.}
\begin{equation*}
\theta_d = \text{mean}_{\text{case}}(\log \mathbf{W}_{dn}) - \text{mean}_{\text{control}}(\log \mathbf{W}_{dn})
\end{equation*}

## Implied Assumptions about Scale

\textcolor{gray}{\textbf{Step 1: Model Sampling Uncertainty}}
\begin{align*}
\textcolor{gray}{\mathbf{Y}_{\cdot n}} &\textcolor{gray}{\sim \text{Multinomial}(\mathbf{W}_{\cdot n}^\parallel)}\\
\textcolor{gray}{\mathbf{W}_{\cdot n}^\parallel} &\textcolor{gray}{\sim \text{Dirichlet}(\alpha)}
\end{align*}


\textbf{Step 2: Centered Log-Ratio Transformation}
\begin{equation*}
\log \mathbf{W}_{\cdot n} = \left[\log \mathbf{W}_{1n}^\parallel - \text{mean}(\log \mathbf{W}_{\cdot n}^\parallel), ..., \log \mathbf{W}_{Dn}^\parallel - \text{mean}(\log \mathbf{W}_{\cdot n}^\parallel) \right]
\end{equation*}

\textcolor{gray}{\textbf{Step 3: Calculate LFCs and Test if Different from Zero.}
\begin{equation*}
\theta_d = \text{mean}_{\text{case}}(\log \mathbf{W}_{dn}) - \text{mean}_{\text{control}}(\log \mathbf{W}_{dn})
\end{equation*}}

  
## Implied Assumptions about Scale, cont.
Since $\log \mathbf{W}_{dn} = \log \mathbf{W}_{dn}^\parallel + \log W_n^\perp$, the CLR normalization implies:

\begin{align*}
\color{gray}{\log W_{dn}} &= \color{gray}{\log \mathbf{W}_{dn}^\parallel - \text{mean}(\log \mathbf{W}_{\cdot n}^\parallel)}\\
\log W_n^\perp &= -\text{mean}(\log \mathbf{W}_{\cdot n}^\parallel).
\end{align*}

\vspace{.25in}
\textcolor{gray}{What does this mean?}


## Unacknowledged bias!

\begin{figure}
  \centering
  \includegraphics[width=4.5in]{figures/unacknowledged_bias.pdf}
\end{figure}

## Adding Uncertainty in Scale can Help.

\begin{figure}
  \centering
  \includegraphics[width=3.25in]{figures/sim-res.pdf}
\end{figure}


# Scale Reliant Inference

## Scale Reliant Inference: The Basics

- **The CoDA perspective:** Research questions that depend on $W^\perp$ (scale) are not possible.

- **The Normalization perspective:** Research questions that depend on $W^\perp$ (scale) can be answered after normalization.

- Who is right?

\textcolor{white}{- **The CoDA perspective:** Yes, but this is limiting in practice.}

\textcolor{white}{- **The Normalization perspective:** Not correct, but attempting to answer relevant questions.}

## Scale Reliant Inference: The Basics

- **The CoDA perspective:** Research questions that depend on $W^\perp$ (scale) are not possible.

- **The Normalization perspective:** Research questions that depend on $W^\perp$ (scale) can be answered after normalization.

- Who is right?

- **The CoDA perspective:** Yes, but this is limiting in practice.

- **The Normalization perspective:** Not correct, but attempting to answer relevant questions.

## Scale Reliant Inference: The Basics

- What happens if $\theta$ depends on $W^\perp$?

- Consider LFCs: how are taxa changing between two conditions?

\begin{align*}
\theta_d &= \text{mean}_{\text{case}}(\log \mathbf{W}_{dn}) - \text{mean}_{\text{control}}(\log \mathbf{W}_{dn})\\
&= ... \\
&= \underbrace{\text{mean}_{\text{case}}(\log \mathbf{W}_{dn}^\parallel) - \text{mean}_{\text{control}}(\log \mathbf{W}_{dn}^\parallel)}_{\theta^\parallel}\\
& \, \, \, \, \, \, + \underbrace{\text{mean}_{\text{case}}(\log W_{n}^\perp) - \text{mean}_{\text{control}}(\log W_{n}^\perp)}_{\theta^\perp}\\
\end{align*}


\textcolor{gray}{Don't we need $\theta^\perp$?}

## Scale Reliant Inference: Theory Intro
Recall for LFCs:
\begin{align*}
\theta_d &= \text{mean}_{\text{case}}(\log \mathbf{W}_{dn} ) - \text{mean}_{\text{control}}(\log \mathbf{W}_{dn} )\\
&= \theta^\parallel + \theta^\perp
\end{align*}

- What can we say about $\theta$ from $\theta^\parallel$ alone?

\textcolor{white}{Statistical perspective: $\theta$ is not identifiable without $\theta^\perp$.}

\textcolor{white}{Practical issues: unbiased estimators, calibrated confidence sets, and type-I error control **NOT** possible!}

  \textcolor{white}{See Nixon et al. (2023) for details.}

## Scale Reliant Inference: Theory Intro
Recall for LFCs:
\begin{align*}
\theta_d &= \text{mean}_{\text{case}}(\log \mathbf{W}_{dn} ) - \text{mean}_{\text{control}}(\log \mathbf{W}_{dn} )\\
&= \theta^\parallel + \theta^\perp
\end{align*}

- What can we say about $\theta$ from $\theta^\parallel$ alone?

- Statistical perspective: $\theta$ is not identifiable without $\theta^\perp$.

- Practical issues: unbiased estimators, calibrated confidence sets, and type-I error control **NOT** possible!

- See Nixon et al. (2023) for details.

## Scale Simulation Random Variables

**Goal:** Estimate $\theta = f(\mathbf{W}^\parallel, W^\perp)$.

\vspace{.25in}

1. Draw samples of $\mathbf{W}^{\parallel}$ from a measurement model (can depend on $\mathbf{Y}$).

2. Draw samples of $W^{\perp}$ from a scale model (can depend on $\mathbf{W}^{\parallel}$).

3. Estimate samples of $\theta = f(\mathbf{W}^\parallel, W^\perp)$.


# Updated ALDEx2 Model

## Rewind: $\theta^\perp$

\textcolor{gray}{\begin{equation*}
\theta^\perp = \text{mean}_{\text{case}}(\log W_{n}^\perp) - \text{mean}_{\text{control}}(\log W_{n}^\perp)
\end{equation*}}

\vspace{.1in}

\textcolor{white}{- The change in scales between conditions matters for estimating LFCs.}

\textcolor{white}{- The scale only needs to be known up to a constant (see Nixon et. al (2023)).}

\textcolor{white}{- Each normalization implies a value of $\theta^\perp$ \textcolor{white}{(e.g., CLR):}}

\textcolor{white}{\begin{equation*}
\theta^\perp_{\text{CLR}} = \text{mean}_{\text{case}}(-\text{GM}( \mathbf{W}_{\cdot n}^\parallel)) - \text{mean}_{\text{control}}(-\text{GM}( \mathbf{W}_{\cdot n}^\parallel)) 
\end{equation*}}

## Rewind: $\theta^\perp$

\textcolor{gray}{\begin{equation*}
\theta^\perp = \text{mean}_{\text{case}}(\log W_{n}^\perp) - \text{mean}_{\text{control}}(\log W_{n}^\perp)
\end{equation*}}

\vspace{.1in}

- The change in scales between conditions matters for estimating LFCs.

- The scale only needs to be known up to a constant (see Nixon et. al (2023)).

\textcolor{white}{- Each normalization implies a value of $\theta^\perp$ \textcolor{white}{(e.g., CLR):}}

\textcolor{white}{\begin{equation*}
\theta^\perp_{\text{CLR}} = \text{mean}_{\text{case}}(-\text{GM}( \mathbf{W}_{\cdot n}^\parallel)) - \text{mean}_{\text{control}}(-\text{GM}( \mathbf{W}_{\cdot n}^\parallel)) 
\end{equation*}}

## Rewind: $\theta^\perp$

\textcolor{gray}{\begin{equation*}
\theta^\perp = \text{mean}_{\text{case}}(\log W_{n}^\perp) - \text{mean}_{\text{control}}(\log W_{n}^\perp)
\end{equation*}}

\vspace{.1in}

- The change in scales between conditions matters for estimating LFCs.

- The scale only needs to be known up to a constant (see Nixon et. al (2023)).

- Each normalization implies a value of $\theta^\perp$ \textcolor{gray}{(e.g., CLR):}

\textcolor{gray}{\begin{equation*}
\theta^\perp_{\text{CLR}} = \text{mean}_{\text{case}}(-\text{GM}( \mathbf{W}_{\cdot n}^\parallel)) - \text{mean}_{\text{control}}(-\text{GM}( \mathbf{W}_{\cdot n}^\parallel)) 
\end{equation*}}


## ALDEx2 as an SSRV

\textcolor{gray}{\textbf{Step 1: Model Sampling Uncertainty}}
\textcolor{gray}{\begin{align*}
\mathbf{Y}_{\cdot n} &\sim \text{Multinomial}(\mathbf{W}_{\cdot n}^\parallel)\\
\mathbf{W}_{\cdot n}^\parallel &\sim \text{Dirichlet}(\alpha)
\end{align*}}

\textbf{Step 2: Draw Samples from a Scale Model}
\begin{align*}
\log W_{n}^\perp &=- \text{mean}(\log \mathbf{W}_{\cdot n}^\parallel) + \epsilon, \, \epsilon \sim N(0,\gamma^2)\\
\log \mathbf{W}_{\cdot n} &= \log \mathbf{W}_{\cdot n}^\parallel + \log W_{n}^\perp
\end{align*}

\textcolor{gray}{\textbf{Step 3: Calculate LFCs and Test if Different from Zero.}}
\textcolor{gray}{\begin{equation*}
\theta_d = \text{mean}_{\text{case}}(\log \mathbf{W}_{dn}) - \text{mean}_{\text{control}}(\log \mathbf{W}_{dn})
  \end{equation*}}

## Benefits of Moving Past Normalizations to Scale

\begin{figure}
  \centering
  \includegraphics[width=3.25in]{figures/sim-res-samples.pdf}
\end{figure}


## Intro to Scale Models

There are no restrictions on what scale models can be, although there are some helpful options:

\vspace{.125in}

1. Based on normalizations. \textcolor{gray}{(Stochastic normalizations)}
2. Based on biological knowledge.
3. Based on outside measurements.

## Scale Models based on Biological Knowledge

What do past studies or biological mechanisms tell about the scale of the system?

\vspace{.1in}

\textcolor{white}{1. You are confident that taking an antibiotic will kill at least some microbes in the gut.}

\textcolor{white}{2. A past study showed that a certain disease (e.g., Crohn's disease) leads to lower microbial load in the gut.}

\textcolor{white}{3. You believe the total microbial load in the mouth changes after brushing your teeth.}

\textcolor{white}{This type of information can be used in scale model building.}

## Scale Models based on Biological Knowledge

What do past studies or biological mechanisms tell about the scale of the system?

\vspace{.1in}

1. You are confident that taking an antibiotic will kill at least some microbes in the gut.

2. A past study showed that a certain disease (e.g., Crohn's disease) leads to lower microbial load in the gut.

3. You believe the total microbial load in the mouth changes after brushing your teeth.

\textcolor{gray}{This type of information can be used in scale model building.}

## Scale Models based on Outside Measurements

How can outside measurements be used to quantify scale?

\vspace{.1in}

\textcolor{white}{1. These measurements can be used *if* they relate to your scale of interest.}

\textcolor{white}{2. Examples include flow cytometry, qPCR, etc.}

\textcolor{white}{3. Scale models can incorporate measurement uncertainty.}

## Scale Models based on Outside Measurements

How can outside measurements be used to quantify scale?

\vspace{.1in}

1. These measurements can be used *if* they relate to your scale of interest.

2. Examples include flow cytometry, qPCR, etc.

3. Scale models can incorporate measurement uncertainty.

# Coding Changes to ALDEx2

## Including scale

**The new ALDEx2 model removes normalizations in lieu of scale models.**

\vspace{.25in}

\textcolor{white}{Major updates:}

\textcolor{white}{1. A new argument `gamma` which makes it easy to incorporate scale uncertainty.}

\textcolor{white}{2. A new function `aldex.senAnalysis` to see how analysis results change as a function of scale uncertainty.}

## Including scale

**The new ALDEx2 model removes normalizations in lieu of scale models.**

\vspace{.25in}

Major updates:

1. A new argument `gamma` which makes it easy to incorporate scale uncertainty.

2. A new function `aldex.senAnalysis` to see how analysis results change as a function of scale uncertainty.

## The gamma argument

- Added as argument to the `aldex` and `aldex.clr` function.

- `gamma` can either be a single numeric or a matrix.
    1. Single numeric: controls the noise on the default scale model.
    2. Matrix: A $N \times S$ matrix of samples of $W^\perp$.
    
- `gamma = NULL` returns the original behavior of ALDEx2.

## Option 1: Default Scale Model

The default scale model is based on errors in the CLR normalization.

$$\log \hat{W}_{n}^{\perp(s)} = - \mathrm{mean} \left(\log \hat{W}^{\parallel (s)}_{\cdot n}\right) + \Lambda^\perp x_{n}$$
$$\Lambda^\perp  \sim \ N(0, \gamma^2).$$

## Advantages of the Default Scale Model

1. It is built off the status quo for ALDEx2.

2. Any value of $\gamma > 0$ will reduce false positives compared to the CLR normalization.

3. It has a concrete interpretation to contextualize scale assumptions.

## Interpreting the Default Scale Model

\textcolor{gray}{$$\log \hat{W}_{n}^{\perp(s)} = - \mathrm{mean} \left(\log \hat{W}^{\parallel (s)}_{\cdot n}\right) + \Lambda^\perp x_{n}$$}
$$\Lambda^\perp  \sim \ N(0, \gamma^2).$$
\vspace{.1in}

**Empirical Rule:** 95\% of the samples of $\Lambda^\perp$ fall within $[-2 \gamma, 2 \gamma]$.

## Interpreting the Default Scale Model, cont.

$$\textcolor{gray}{\log \hat{W}_{n}^{\perp(s)} = - \mathrm{mean} \left(\log \hat{W}^{\parallel (s)}_{\cdot n}\right) +} \Lambda^\perp x_{n}$$
\textcolor{gray}{$$\Lambda^\perp  \sim \ N(0, \gamma^2).$$}

\vspace{.1in}
**For case/control experiments:** 

  1. If $x_n = 1$: add $\Lambda^\perp$ \textcolor{gray}{(95\% of samples of $\log \hat{W}_{n}^{\perp(s)}$ fall within $[- \mathrm{mean} \left(\log \hat{W}^{\parallel (s)}_{\cdot n}\right) - 2 \gamma, - \mathrm{mean} \left(\log \hat{W}^{\parallel (s)}_{\cdot n}\right) + 2 \gamma]$.)}
  
  2. If $x_n = 0$: no noise added \textcolor{gray}{($\log \hat{W}_{n}^{\perp(s)} = - \mathrm{mean} \left(\log \hat{W}^{\parallel (s)}_{\cdot n}\right)$)}.

## Interpreting the Default Scale Model, cont.

\begin{align*}
\textcolor{gray}{\theta^\perp_{\text{Default Scale}}} &\textcolor{gray}{= \text{mean}_{\text{case}}(-\text{GM}( \mathbf{W}_{\cdot n}^\parallel)) - \text{mean}_{\text{control}}(-\text{GM}( \mathbf{W}_{\cdot n}^\parallel)) + \Lambda^\perp}\\
&= \textcolor{gray}{\theta^\perp_{\text{CLR}} + \Lambda^\perp}
\end{align*}

Taken together, the default scale model implies that:

\vspace{.1in}

\textcolor{white}{1. The value of $\theta^\perp$ is within $\pm 2 \gamma$ of the value of $\theta^\perp_{\text{CLR}}$ implied by the CLR normalization.}

\textcolor{white}{2. With 95 certainty, the true difference in scales falls within the the range $2^{\theta_{\text{CLR}}^\perp \pm 2 \gamma}$.} 

## Interpreting the Default Scale Model, cont.

\begin{align*}
\textcolor{gray}{\theta^\perp_{\text{Default Scale}}} &\textcolor{gray}{= \text{mean}_{\text{case}}(-\text{GM}( \mathbf{W}_{\cdot n}^\parallel)) - \text{mean}_{\text{control}}(-\text{GM}( \mathbf{W}_{\cdot n}^\parallel)) + \Lambda^\perp}\\
&= \textcolor{gray}{\theta^\perp_{\text{CLR}} + \Lambda^\perp}
\end{align*}

Taken together, the default scale model implies that:

\vspace{.1in}

1. The value of $\theta^\perp$ is within $\pm 2 \gamma$ of the value of $\theta^\perp_{\text{CLR}}$ implied by the CLR normalization.

2. With 95% certainty, the true difference in scales falls within the the range $2^{\theta_{\text{CLR}}^\perp \pm 2 \gamma}$.

## Option 2: More Complex Scale Models

Alternatively, can pass a matrix of scale samples to `gamma` so long as:

1. The dimension is $N \times S$.
2. They are samples of $W^\perp$ not $\log W^\perp$.

Reasons to do this:

1. **Biological beliefs:** Scale is guided by the biological system or the researcher's prior beliefs.

2. **Outside Measurements:** These can be used in building a scale model *if* they are informative on the scale of interest (e.g., qPCR, flow cytometry).

## Sensitivity Analyses

- Instead of picking $\gamma$, why not test over a range instead?


## Sensitivity Analyses

\textcolor{gray}{\textbf{Step 1: Model Sampling Uncertainty}}
\textcolor{gray}{\begin{align*}
\mathbf{Y}_{\cdot n} &\sim \text{Multinomial}(\mathbf{W}_{\cdot n}^\parallel)\\
\mathbf{W}_{\cdot n}^\parallel &\sim \text{Dirichlet}(\alpha)
\end{align*}}

\textbf{Step 2: Draw Samples from a Scale Model}
For a given $\gamma$:
\begin{align*}
\log W_{n}^{\perp, \gamma} &= - \mathrm{mean} \left(\log \hat{W}^{\parallel (s)}_{\cdot n}\right) + \Lambda^\perp x_{n}\\
\Lambda^\perp  &\sim \ N(0, \gamma^2)\\
\log \mathbf{W^\gamma}_{\cdot n} &= \log \mathbf{W}_{\cdot n}^\parallel + \log W_{n}^{\perp, \gamma}
\end{align*}

\textcolor{gray}{\textbf{Step 3: Calculate LFCs and Test if Different from Zero.}}
  
\textbf{Step 4: Repeat for all desired values of $\gamma$.}


# Data Examples

## Simulation Study

Consider a simple study of the microbiome pre/post antibiotic administration.

  - **Research question:** Which taxa change in absolute abundance after taking an antibiotic?
  
  - 100 study participants, 50 in each condition (pre/post antibiotics).
  
  - 20 taxa total with 4 taxa truly changing \textcolor{gray}{(decreasing)}
  
## Data

\begin{figure}
  \centering
  \includegraphics[width=4in]{figures/sim-data.pdf}
\end{figure}

```{r, echo = FALSE, message=FALSE, warning = FALSE}
###R script to analyze the simulated data

library(ALDEx2)
library(tidyverse)
library(ggplot2)
library(ggpattern)
library(cowplot)

set.seed(12345)
##Reading in data (see "data_simulation.R" for details.)
rdat <- read.csv(file.path("Part 2 - Updates to ALDEx2/data/simulation/sim_seq_dat.csv"))

##Reading in the simulated flow data for building a scale model
flow_data <- read.csv(file.path("Part 2 - Updates to ALDEx2/data/simulation/sim_flow_dat.csv"))

## "Y" represents the OTU table
Y <- t(rdat[,-1])

##Vector denoting whether samples was in pre- or post- antibiotic condition.
conds <- as.character(rdat[,1])


## Fitting and analyzing the original ALDEx2 model
mod.base <- aldex(Y, conds, gamma = NULL)


## Recreating ALDEx2
mod.clr <- aldex(Y, conds, gamma = 1e-3)


## Adding noise via the default scale model
mod.ss <- aldex(Y, conds, gamma = .25)
```

## Adding Scale is Easy

```{r, message=FALSE, warning = FALSE}
## Adding noise via the default scale model
mod.ss.high <- aldex(Y, conds, gamma = 0.5)
```

## Investigating Assumptions about Scale

```{r, message=FALSE, warning = FALSE}
## Looking at the implied scale
clr <- aldex.clr(Y, conds, gamma = 1e-3)
clr@scaleSamps[1:6,1:4]
```

## Investigating Assumptions about Scale, cont.

```{r, echo = FALSE, fig.dim = c(3,2)}
clr.dat <- data.frame("group" = conds, "scale" = clr@scaleSamps[,1])
ggplot(clr.dat, aes(x=group, y=scale)) + 
  geom_boxplot() +
  xlab("Condition") +
  ylab("Implied Value of Scale") +
  theme_bw()
```

## Scale Model based on Biology

```{r, tidy = TRUE}
##Creating an informed model using biological reasoning
scales <- c(rep(1, 50), rep(0.9, 50))
scale_samps <- aldex.makeScaleMatrix(gamma = .15, mu = scales, conditions = conds, log=FALSE)

mod.know <- aldex(Y, conds, gamma = scale_samps)
```

## Scale Model based on Outside Measurements

```{r}
flow_data_collapse <- flow_data %>%
  group_by(sample) %>%
  mutate(mean = mean(flow)) %>%
  mutate(stdev = sd(flow)) %>%
  dplyr::select(-flow) %>%
  ungroup() %>%
  unique()
scale_samps <- matrix(NA, 
                      nrow = nrow(flow_data_collapse), 
                      ncol = 128)
for(i in 1:nrow(scale_samps)){
  scale_samps[i,] <- rnorm(n= 128, mean = flow_data_collapse$mean[i], sd =flow_data_collapse$stdev[i])
}
mod.flow <- aldex(Y, conds, gamma = scale_samps)
```

## Plotting Results
```{r, echo = FALSE, message=FALSE, warning = FALSE, out.width = "95%"}
####Plotting and bringing it all together

##Reading in the true data
dat <- read.csv(file.path("Part 2 - Updates to ALDEx2/data/simulation/sim_obs_dat.csv"))


## Helper functions
##Function to label True/false positive/negatives
sig_code <- function(sig, Taxa, truth){
  out <- rep("TN", length(Taxa))
  out[sig &(Taxa %in% truth)] <- "TP" # True Positives
  out[sig & (out!="TP")] <- "FP" # False Positives
  out[!sig & (Taxa %in% truth)] <- "FN" # False Negatives
  return(out)
}

##Function to summarize aldex2 output
summary_aldex2 <- function(fit, pval = 0.05){
  fit %>%
    as.data.frame() %>%
    rownames_to_column("category") %>%
    dplyr::select(category, effect, we.ep, we.eBH) %>%
    mutate(padj=we.eBH) %>%
    mutate(mean=effect) %>%
    mutate(low=NA, high=NA) %>%
    mutate(sig = ifelse(padj <= pval, TRUE, FALSE))
}

##Function to create the grid plot
plot_sig2 <- function(rrs, truth, ...){
  names(rrs) <- model.names[names(rrs)]
  bind_rows(rrs, .id="Model") %>%
    dplyr::select(Model, category, sig) %>%
    mutate(Taxa = category) %>%
    mutate(Taxa=as.numeric(sub("Taxa", "", Taxa))) %>%
    mutate(sigcode = sig_code(sig, Taxa, truth)) %>%
    mutate(Taxa=factor(Taxa), sigcode=factor(sigcode,
                                             levels=c("TP", "TN",
                                                      "FP", "FN"))) %>%
    mutate(Model=factor(Model, levels=model.name.levels)) %>%
    ggplot(aes(x=Taxa, y=Model)) +
    geom_tile_pattern(aes(fill=sigcode, pattern = sigcode), color="darkgrey",pattern_fill = 'grey',pattern_colour  = 'grey', pattern_density = 0.015) +
    theme_minimal() +
    theme(panel.grid = element_blank(),
          legend.title=element_blank(),
          text = element_text(size=16),
          axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
    scale_pattern_manual(values = c(TP = "none", TN = "none", FP = "none", FN = "stripe")) +
    scale_fill_manual(values= c("black", "white", "grey", "white"))
}

##Plotting the results
##Pvalue at default of 0.05

p1 <- gather(dat, Taxa, Count, -Condition) %>%
  mutate(Taxa=as.numeric(sub("Taxa", "", Taxa))) %>%
  mutate(Taxa=factor(Taxa)) %>%
  ggplot(aes(x=Taxa, y=Count)) +
  geom_boxplot(aes(fill = Condition, color = Condition), position=position_dodge(width=1),
               size=1)+
  scale_y_log10() +
  theme_bw() +
  scale_color_manual(values = c("#E64B35FF", "#4DBBD5FF")) +
  scale_fill_manual(values = c("#E64B35FF", "#4DBBD5FF"))+
  labs(color='Antibiotic\nTreatment') +
  labs(fill='Antibiotic\nTreatment') +
  theme(axis.title.x = element_blank(),
        axis.text.x = element_blank(),
        axis.ticks.x=element_blank(),
        text = element_text(size=16))

truth <- c(3,4,15,20)##Locations of the differences

model.names <- c("mod.base"="ALDEx2 (Original)",
                 "mod.clr" = "Default Model (gamma = 1e-3)",
                 "mod.ss"= "Default Model (gamma = 0.25)","mod.ss.high"= "Default Model (gamma = 0.50)",
                 "mod.know" = "Knowledged-Based Model",
                 "mod.flow" = "Flow-Based Model")
model.name.levels <- c("Flow-Based Model", "Knowledged-Based Model", "Default Model (gamma = 0.50)", "Default Model (gamma = 0.25)",  "Default Model (gamma = 1e-3)", "ALDEx2 (Original)")

rrs <- list(mod.base=summary_aldex2(mod.base), 
            mod.clr = summary_aldex2(mod.clr),
            mod.ss = summary_aldex2(mod.ss),
            mod.ss.high = summary_aldex2(mod.ss.high),
            mod.know = summary_aldex2(mod.know),
            mod.flow = summary_aldex2(mod.flow))

p2 <- plot_sig2(rrs, truth=truth)
p <- plot_grid(p1, p2, nrow=2, align="v", rel_heights=c(1.7, 1))
p
```

## Sensitivity Analyses

```{r, eval = FALSE}
##First, specifying different values for the noise in the scale
gamma_to_test <- c(1e-3, seq(0.1,1,by=.1))

##Run the CLR function
clr <- aldex.clr(Y, conds)

##Run sensitivity analysis function
sen_res <- aldex.senAnalysis(clr, gamma = gamma_to_test)
plotGamma(sen_res, thresh = .1, 
          blackWhite = TRUE, taxa_to_label =  3)
```

## Sensitivity Analyses, cont.

\begin{figure}
  \centering
  \includegraphics[width=4in]{figures/sim_gamma.pdf}
\end{figure}


## Real Example: Vandputte

1. Comparison study of 29 Crohn's disease patients and 66 healthy controls.

2. For each patient, they sequenced the fecal sample and obtained flow cytometry measurements.

3. Proposed an approach that supplemented sequence count data with flow cytometry measurements.


```{r, echo = FALSE, warning = FALSE, message = FALSE}

# Analysis----------------------------------------------------------------------

## Loading libraries
library(phyloseq) #
library(tidyverse) #
library(ALDEx2) #
library(gghighlight)
library(cowplot)
library(ggplot2)
library(ggpattern)
library(magrittr)
library(stringi)
library(phyloseq)
library(data.table)
library(DESeq2)
library(latex2exp)
library(ggrepel)
library(gghighlight)
set.seed(12345)
```

## Difference in Scale Implied by Flow Cytometry
```{r, echo = FALSE, warning = FALSE, message = FALSE, out.width = "95%"}
## Plotting the flow cytometry data
phylo <- readRDS(file.path("C:\\Users\\map5672\\OneDrive - The Pennsylvania State University\\Documents 1\\GitHub\\michellepistner\\glbio-2024-scale-workshop\\Part 2 - Updates to ALDEx2\\data\\vandputte\\vandputte_phyloseq.RDS"))
library(phyloseq)
sample_data(phylo) %>% 
  data.frame() %>%
  dplyr::select(Health.status, CellCount) %>%
  ggplot(aes(x = Health.status, y = CellCount)) +
  geom_boxplot() +
  xlab("Cohort") +
  ylab("Flow Cytometry Measurement")
```

## Difference in Scale Implied by CLR
```{r, echo = FALSE, warning = FALSE, message = FALSE, out.width = "95%"}
## Estimate of \theta^\perp from the original ALDEx2 model
clr <- aldex.clr(t(otu_table(phylo)), sample_data(phylo)$Health.status, mc.samples = 1000, denom = "all", gamma = 1e-3)
clr.dat <- data.frame("group" = sample_data(phylo)$Health.status, "scale" = clr@scaleSamps[,1])
ggplot(clr.dat, aes(x=group, y=scale)) + 
  geom_boxplot() +
  xlab("Cohort") +
  ylab("Implied Value of Scale")
```


```{r, echo = FALSE, warning = FALSE, message = FALSE, results = FALSE}
library(gghighlight)
library(ggrepel)
#-------------------------------------------------------------------------------
aldex.lfc <- function(clr){
  # Use clr conditions slot instead of input
  if (is.vector(clr@conds)) {
    conditions <- clr@conds
  } else if (is.factor(clr@conds)) {
    if (length(levels(clr@conds) == 2)) {
      conditions <- clr@conds
    }
  } else if (is.matrix(clr@conds)){
    stop("currently does not support > 2 conditions.")
  } else {
    stop("please check that the conditions parameter for aldex.clr is correct.")
  }
  
  nr <- numFeatures(clr) # number of features
  rn <- getFeatureNames(clr) # feature names
  mc.s <- numMCInstances(clr)
  p <- length(conditions)
  # ---------------------------------------------------------------------
  
  # sanity check to ensure only two conditons passed to this function
  conditions <- as.factor( conditions )
  levels     <- levels( conditions )
  
  sets <- levels
  setA <- which(conditions == sets[1])
  setB <- which(conditions == sets[2])
  
  
  ## we need to fill an array and calculate these statistics over the array
  W.est <- array(NA, dim = c(nr, p, mc.s))
  
  for(i in 1:p){
    W.est[,i,] <- getMonteCarloReplicate(clr, i)
  }
  print(paste0("Condition A is ", sets[1], " and condition B is ", sets[2], "."))
  lfc <- rep(NA, mc.s)
  lfc <- apply(W.est, MARGIN = 3, FUN = function(mat, setA, setB){rowMeans(mat[,setA]) - rowMeans(mat[,setB])}, setA =setA, setB = setB)
  return(data.frame("lfc" = rowMeans(lfc), "sd" = apply(lfc,1,sd), "p2.5" = apply(lfc,1,quantile, probs = c(0.025)), "p97.5" = apply(lfc,1,quantile, probs = c(.975))))
}

## ALDEx2 models----------------------------------------------------------------
## First aldex2
Y <- t(otu_table(phylo)) 
X <- sample_data(phylo)$Health.status

##Default scale model
aldex_fit <- aldex(Y,X,mc.samples = 1000, gamma = .5)

tax_default = aldex_fit %>% 
  rownames_to_column("category") %>%
  dplyr::select(category, effect, we.ep, we.eBH) %>%
  mutate(pval = we.ep) %>%
  mutate(padj = we.eBH) %>%
  dplyr::filter(padj < 0.05)

##Gold standard flow cytometry model

## Choosing scale based off of the estimated technical variation from the other methods. See "Data" for the calculation in the excel file "41586_2017_BFnature24460_MOESM11_ESM.xlsx"
## Doing a sensitivity analysis as well
sen_res <- list()
scale_mean <- log2(sample_data(phylo)$CellCount)
gamma <-  c(1e-3,.1,.25,.5,0.7,1,1.5,2, 3,4,5,6,7,8,9,10)
for(j in 1:length(gamma)){
  scale_var <- rep(gamma[j], 95)
  
  scale_samples <- matrix(NA, nrow = 95, ncol = 1000)
  for(i in 1:95){
    scale_samples[i,] <- 2^rnorm(1000, scale_mean[i], scale_var[i])
  }
  clr <- aldex.clr(Y,X, gamma = scale_samples,mc.samples = 1000)
  res <- aldex.ttest(clr)
  res <- cbind(res, aldex.lfc(clr))
  sen_res[[j]] <- res
}

## Creating the graph data frame
effect <- c()
effect.low <- c()
effect.high <- c()
lfc.sd <- c()
gam_used <- c()
we.eBH <- c()
tax <- c()

for(i in 1:length(sen_res)){
  gam_used <- c(gam_used, rep(gamma[i], nrow(sen_res[[i]])))
  effect <- c(effect, sen_res[[i]]$lfc)
  effect.low <- c(effect.low, sen_res[[i]]$p2.5)
  effect.high <- c(effect.high, sen_res[[i]]$p97.5)
  lfc.sd <- c(lfc.sd, sen_res[[i]]$sd)
  we.eBH <- c(we.eBH, sen_res[[i]]$we.eBH)
  tax <- c(tax, rownames(sen_res[[i]]))
}

graph.df <- data.frame("gamma" = gam_used, "effect" = effect, "we.eBH" = we.eBH, "Sequence" = tax, "low" = effect.low, "high" = effect.high, "sd" = lfc.sd)

tax_merge <- as.data.frame(tax_table(phylo)) %>%
  rownames_to_column("Sequence") %>%
  dplyr::select(Sequence, Genus)

graph.df <- graph.df %>%
  mutate(effect = -1*effect/sd) %>%
  plyr::join(tax_merge, by = "Sequence") %>%
  mutate(Genus = ifelse(Genus == "Escherichia/Shigella", "Escherichia", Genus)) %>%
  mutate(label = ifelse((we.eBH < 0.05), Genus, NA)) %>%
  group_by(label) %>%
  mutate(gamma.max = max(gamma)) %>%
  mutate(label = ifelse((!is.na(label)) & (gamma == gamma.max), label, NA)) %>%
  mutate(label = ifelse((!is.na(label)) & (gamma <= 6), label, NA)) %>%
  mutate(label = ifelse(label %in% c("Anaerobutyricum", "Sutterella", "Parabacteroides"), label, NA))

gam_diag <- ggplot(graph.df, aes(x = gamma, y = effect, group = Genus)) +
  geom_line () +
  gghighlight(we.eBH < 0.05) +
  ylab("Standardized Log Fold Change") +
  xlab(expression(gamma)) +
  theme(text = element_text(size=28)) +
  theme_bw() +
  geom_label_repel(aes(label = label),
                   na.rm = TRUE, size=3, direction='y') 


## Choosing scale based off of the estimated technical variation from the other methods. See "Data" for the calculation in the excel file "41586_2017_BFnature24460_MOESM11_ESM.xlsx"
tax_scale = sen_res[[5]] %>% 
  rownames_to_column("category") %>%
  mutate(pval = we.ep) %>%
  mutate(padj = we.eBH) %>%
  dplyr::filter(padj < 0.05)
```

## Creating a Gold Standard Model
```{r, eval = FALSE}
scale_mean <- log2(sample_data(phylo)$CellCount)
scale_var <- rep(0.7, 95)
  
scale_samples <- matrix(NA, nrow = 95, ncol = 1000)
for(i in 1:95){
  scale_samples[i,] <- 2^rnorm(1000, scale_mean[i], scale_var[i])
}
```


## Creating an Informed Model

```{r, warning = FALSE, message = FALSE}
scale.cd <- 2^matrix(rnorm(1000*29, mean = log2(.7), sd = .125), nrow = 29)
scale.control <- 2^matrix(rnorm(1000*66, mean = log2(1), sd = .125), nrow = 66)

scale.inf <- rbind(scale.cd, scale.control)
aldex_informed <- aldex(Y,X,mc.samples = 1000, gamma = scale.inf)
```

```{r, echo = FALSE, warning = FALSE, message = FALSE}
tax_informed = aldex_informed %>% 
  rownames_to_column("category") %>%
  dplyr::select(category, effect, we.ep, we.eBH) %>%
  mutate(pval = we.ep) %>%
  mutate(padj = we.eBH) %>%
  dplyr::filter(padj < 0.05)

#-------------------------------------------------------------------------------

## Other methods ---------------------------------------------------------------
library(DESeq2)
library(edgeR)
## DeSeq2
coldata <- matrix(sample_data(phylo)$Health.status, ncol = 1)
colnames(coldata) <- "Condition"
dds <- DESeqDataSetFromMatrix(countData=as.matrix(Y@.Data + 1),
                              colData=coldata,
                              design = ~Condition)
dds <- DESeq(dds)
res <- results(dds)
tax_deseq <- res %>% 
  as.data.frame() %>% 
  rownames_to_column("category") %>% 
  dplyr::select(category, log2FoldChange, padj, lfcSE) %>% 
  mutate(sig = ifelse(padj < 0.05, TRUE, FALSE)) %>%
  dplyr::filter(sig == TRUE)


##EdgeR

Y <- t(otu_table(phylo))
X <- sample_data(phylo)$Health.status
conds <- sample_data(phylo)$Health.status 
coldata <- ifelse(conds == "CD", 0, 1)
coldata <- matrix(coldata, ncol = 1)

y <- DGEList(counts=as.matrix(Y@.Data +1),group=c(coldata[,1]))
y <- calcNormFactors(y)
y <- estimateDisp(y)
et <- exactTest(y)
tax_edgeR <- topTags(et, n=1600, p.value = 1) %>%
  as.data.frame() %>%
  rownames_to_column("category") %>%
  mutate(sig = ifelse(FDR < 0.05, TRUE, FALSE)) %>%
  dplyr::filter(sig == TRUE)

#-------------------------------------------------------------------------------

## vandpuette's qmp method------------------------------------------------------

# function from https://github.com/raeslab/QMP/blob/master/QMP.R
# with cnv_corrected_abundance_table: a copy number variation corrected abundance table with sample-identifiers as rows, copy number corrected taxa-abundances as columns
# with cell_counts_table: a table with sample-identifiers as rows, cell counts as columns 
rarefy_even_sampling_depth <- function(cnv_corrected_abundance_table, cell_counts_table) 
{
  try(if(all(row.names(cnv_corrected_abundance_table) == row.names(cell_counts_table))==FALSE) stop("Cnv_corrected_abundance_table and cell_counts_table do not have the same sample-names, Please check!"))
  cnv_corrected_abundance_table = ceiling(cnv_corrected_abundance_table) # data values are rounded up in order to make use of integer values during the calculations
  cell_counts_table = t(cell_counts_table[row.names(cnv_corrected_abundance_table),]) # make sure the order of the samples is the same in both files    
  sample_sizes = rowSums(cnv_corrected_abundance_table) # sample size of each sample (total nr of reads)
  sampling_depths = sample_sizes / cell_counts_table # sampling depth of each sample (total nr of reads divided by the cell count)
  minimum_sampling_depth = min(sampling_depths) # minimum of all sampling depths
  rarefy_to = cell_counts_table * minimum_sampling_depth # nr of reads to rarefy in each sample in order to get to an even sampling depth over all samples
  cnv_corrected_abundance_table_phyloseq = otu_table(cnv_corrected_abundance_table, taxa_are_rows = FALSE) # convert to phyloseq otutable
  rarefied_matrix=matrix(nrow = nrow(cnv_corrected_abundance_table_phyloseq), ncol = ncol(cnv_corrected_abundance_table_phyloseq), dimnames = list(rownames(cnv_corrected_abundance_table_phyloseq), colnames(cnv_corrected_abundance_table_phyloseq)))
  for (i in 1:nrow(cnv_corrected_abundance_table_phyloseq))
  {
    x <- rarefy_even_depth(cnv_corrected_abundance_table_phyloseq[i,], sample.size = rarefy_to[i], rngseed = 711, replace = FALSE, trimOTUs = F, verbose = FALSE)
    rarefied_matrix[i,] = x
  }
  normalised_rarefied_matrix = rarefied_matrix/rowSums(rarefied_matrix)
  QMP = normalised_rarefied_matrix*cell_counts_table[1,]
  return(QMP)
}
cellCounts <- data.frame(sample_data(phylo)) %>%
  dplyr::select(CellCount)
QMP_df <- rarefy_even_sampling_depth(otu_table(phylo),cellCounts)

## running a wilcoxon test on the qmp data
p.qmp <- rep(NA, ncol(QMP_df))
lfc.qmp <- rep(NA, ncol(QMP_df))
conds <- sample_data(phylo)$Health.status
for(i in 1:length(p.qmp)){
  x <- log2(QMP_df[which(conds == "CD"),i]+0.5)
  y <- log2(QMP_df[which(conds == "Control"),i]+0.5)
  lfc.qmp[i] <- mean(x) - mean(y)
  tmp.test <- t.test(x,y)
  p.qmp[i] <- tmp.test$p.value
}
padj.qmp <- p.adjust(p.qmp, method = "BH")

tax_QMP <- data.frame("category" = colnames(otu_table(phylo)),
                      "pval" = p.qmp,
                      "padj" = padj.qmp) %>%
  mutate(sig = ifelse(padj.qmp <= 0.05, TRUE, FALSE)) %>%
  dplyr::filter(sig == TRUE)

#-------------------------------------------------------------------------------
```

## Comparing to Other Methods

```{r, echo = FALSE, warning = FALSE, message = FALSE, out.width = "95%"}
## Plotting---------------------------------------------------------------------
sig.values = c(tax_edgeR$category,tax_deseq$category, tax_scale$category, tax_informed$category, tax_QMP$category, tax_default$category) %>% unique

###Some light processing to make it more useful

truth.pos = tax_scale$category

##Generating the grid plot
q=length(sig.values)

sig.df = data.frame("Sequence" = rep(sig.values,6))
sig.df = sig.df %>%
  mutate(true.pos = ifelse(Sequence %in% truth.pos, 1, 0)) %>%
  mutate(Model = c( rep("ALDEx2 (Gold Standard)", q), rep("ALDEx2 (Informed)", q), rep("ALDEx2 (Default Scale)", q), rep("QMP", q),rep("DESeq2", q), rep("edgeR", q))) %>%
  mutate(sigcode = c( ifelse(sig.values %in% tax_scale$category, 1, 0),ifelse( sig.values %in% tax_informed$category, 1, 0),ifelse( sig.values %in% tax_default$category, 1, 0), ifelse( sig.values %in% tax_QMP$category, 1, 0),ifelse( sig.values %in% tax_deseq$category, 1, 0), ifelse( sig.values %in% tax_edgeR$category, 1, 0))) %>%
  mutate(res = ifelse(true.pos == 1 & sigcode == 1, "TP", NA)) %>%
  mutate(res = ifelse(true.pos == 0 & sigcode == 0, "TN", res)) %>%
  mutate(res = ifelse(true.pos == 1 & sigcode == 0, "FN", res)) %>%
  mutate(res = ifelse(true.pos == 0 & sigcode == 1, "FP", res)) %>%
  mutate(sigcode = factor(sigcode, levels = list("Non. Sig."="0", "Sig."="1")))


sig.df$Model = factor(sig.df$Model, levels=c( "edgeR", "DESeq2","QMP","ALDEx2 (Default Scale)", "ALDEx2 (Informed)", "ALDEx2 (Gold Standard)"))

tax_merge <- as.data.frame(tax_table(phylo)) %>%
  rownames_to_column("Sequence") %>%
  dplyr::select(Sequence, Genus)

sig.df <- sig.df %>%
  plyr::join(tax_merge, by = "Sequence") %>%
  mutate(Genus = ifelse(Genus == "Escherichia/Shigella", "Escherichia", Genus)) 
##No color labels
p1 = ggplot(sig.df, aes(x=Genus, y=Model)) +
  geom_tile_pattern(aes(fill=res, pattern = res), color="black",pattern_fill = 'black', pattern_colour  = 'black', pattern_density = 0.015) +
  theme_minimal(18) +
  labs(title = "") +
  theme(panel.grid = element_blank(), 
        legend.title=element_blank(),
        legend.key.size = unit(.825, "cm"),
        text = element_text(size=20)) +
  scale_pattern_manual(values = c(TP = "none", TN = "none", FP = "stripe", FN = "stripe")) +
  scale_fill_manual(values= c("white", "lightgrey", "white", "grey")) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
p1
```

## Sensitivity Analyses

```{r, echo = FALSE, out.width="95%"}
gam_diag
```

## References

**Scale Reliant Inference/Updates to ALDEx2:**

- Nixon, et. al. (2023) "Scale Reliant Inference." *ArXiv Preprint 2201.03616*.

- Gloor, Nixon, and Silverman. (2023) "Scale is Not What You Think; Explicit Scale Simulation in ALDEx2." *BioRXiv Preprint 2023.10.21.563431*.

- Nixon, Gloor, and Silverman. (2024) "Beyond Normalizations: Incorporating Scale Uncertainty in ALDEx2." *BioRXiv Preprint 2024.04.01.587602*.

- Fernandes et. al. (2014). "Unifying the analysis of high-throughput sequencing datasets: characterizing
RNA-seq, 16S rRNA gene sequencing and selective growth experiments by compositional data analysis." *Microbiome*.

## References

**Data Sources:**

- McMurrough et. al. (2014)."Control of catalytic efficiency by a coevolving network of catalytic and noncatalytic residues." *PNAS*.

- Vandputte et. al. (2017). "Quantitative microbiome profiling links gut community variation to microbial load." *Nature*.